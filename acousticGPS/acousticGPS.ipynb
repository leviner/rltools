{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPS from raw files\n",
    "\n",
    "## pyEcholab\n",
    "\n",
    "Using the [`pyEcholab`](https://github.com/CI-CMG/pyEcholab.git) toolkit developed by NOAA for reading echosounder data, to pull nmea data from EK60 raw files, you can install directly from the repository:\n",
    "\n",
    "```python\n",
    "!pip install git+https://github.com/CI-CMG/pyEcholab.git\n",
    "```\n",
    "\n",
    "This is setup to use pyEcholab rather than [`echoPype`](https://echopype.readthedocs.io/en/latest/index.html) which uses an intermediate step of forming the netCDF structure. Pulling the lat/lon with `echoPype` will be included as an example at the bottom of the notebook at some point.\n",
    "\n",
    "The downside of the setup below is that it doesn't write out the file until it's done, but that is the trade off for maintaining iterations intervals of < 2s. File building within the loop exponentially increases iteration time due to loading the document and essentially having to read the dataframe twice each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from echolab2.instruments import EK60\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of what the `positions` dictionary produced from echolab looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': array([nan, nan, nan, ..., nan, nan, nan]),\n",
       " 'longitude': array([nan, nan, nan, ..., nan, nan, nan]),\n",
       " 'ping_time': array(['2019-07-02T19:31:41.346', '2019-07-02T19:31:43.395',\n",
       "        '2019-07-02T19:31:44.424', ..., '2019-07-21T17:52:34.230',\n",
       "        '2019-07-21T17:52:34.408', '2019-07-21T17:52:34.588'],\n",
       "       dtype='datetime64[ms]')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do this using only pandas to build a list of dictionaries and combining at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db737f03c2ab423d94da27bd331c76d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rawfiles = sorted(glob('D:\\AIESII\\OS201901\\EK60_Data\\*.raw'))\n",
    "df_list= []\n",
    "for i in trange(10):\n",
    "    ek60 = EK60.EK60()\n",
    "    ek60.read_raw(rawfiles[i])\n",
    "    rawd = ek60.get_raw_data(channel_number=1)\n",
    "    sv = rawd.get_Sv()\n",
    "    positions = ek60.nmea_data.interpolate(sv, 'position')\n",
    "    dfGPS = pd.DataFrame(positions)\n",
    "    df_list.append(dfGPS)\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly faster method which uses `dask.delayed` rather than converting each dataframe to pd.DataFrame within the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf363e9eec24fb6ba49821aea08f3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1976), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\AIESII\\OS201901\\EK60_Data\\OceanStarr_2019-D20190825-T104936.raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "rawfiles = sorted(glob('D:\\AIESII\\OS201901\\EK60_Data\\*.raw'))\n",
    "df_list= []\n",
    "for i in trange(2000,len(rawfiles)):\n",
    "    try:\n",
    "        ek60 = EK60.EK60()\n",
    "        ek60.read_raw(rawfiles[i])\n",
    "        rawd = ek60.get_raw_data(channel_number=1)\n",
    "        sv = rawd.get_Sv()\n",
    "        positions = ek60.nmea_data.interpolate(sv, 'position')\n",
    "        dfGPS = dask.delayed(pd.DataFrame)(positions)\n",
    "        df_list.append(dfGPS)\n",
    "    except:\n",
    "        print(rawfiles[i])\n",
    "df = dask.delayed(pd.concat)(df_list).compute()\n",
    "df.to_csv('D:\\AIESII\\OS201901\\gps\\gps3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running this, I split it up into 3 parts because I wasn't sure how long it would take and I was worried originally it would fail. I had one file (printed above via the exception) that I manually exported gps from Echoview and formatted spreadsheet to match the headers. Then I read them all back in into a big sheet, dropped the missing lat/lon points, dropped the index column, and sorted by datetime of the ping. This is then saved to the final data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ping_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4169</td>\n",
       "      <td>2019-07-19 19:36:56.394</td>\n",
       "      <td>47.666748</td>\n",
       "      <td>-122.391758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>2019-07-19 19:36:57.414</td>\n",
       "      <td>47.666748</td>\n",
       "      <td>-122.391758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4171</td>\n",
       "      <td>2019-07-19 19:36:58.434</td>\n",
       "      <td>47.666749</td>\n",
       "      <td>-122.391758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4172</td>\n",
       "      <td>2019-07-19 19:36:59.454</td>\n",
       "      <td>47.666751</td>\n",
       "      <td>-122.391759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4173</td>\n",
       "      <td>2019-07-19 19:37:00.475</td>\n",
       "      <td>47.666751</td>\n",
       "      <td>-122.391760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ping_time   latitude   longitude\n",
       "4169 2019-07-19 19:36:56.394  47.666748 -122.391758\n",
       "4170 2019-07-19 19:36:57.414  47.666748 -122.391758\n",
       "4171 2019-07-19 19:36:58.434  47.666749 -122.391758\n",
       "4172 2019-07-19 19:36:59.454  47.666751 -122.391759\n",
       "4173 2019-07-19 19:37:00.475  47.666751 -122.391760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.read_csv('D:\\AIESII\\OS201901\\gps\\gps1.csv',parse_dates=['ping_time']).dropna()\n",
    "df2 = pd.read_csv('D:\\AIESII\\OS201901\\gps\\gps2.csv',parse_dates=['ping_time']).dropna()\n",
    "df3 = pd.read_csv('D:\\AIESII\\OS201901\\gps\\gps3.csv',parse_dates=['ping_time']).dropna()\n",
    "df4 = pd.read_csv('D:\\AIESII\\OS201901\\gps\\gpsFail.csv',parse_dates=['ping_time']).dropna()\n",
    "dft = pd.concat([df1,df2,df3,df4], axis=0, sort=True)\n",
    "dft = dft[['ping_time','latitude','longitude']]\n",
    "dft = dft.sort_values('ping_time')\n",
    "dft = dft[dft.ping_time > '2019-08-01']\n",
    "display(dft.head())\n",
    "dft.to_csv('D:\\AIESII\\OS201901\\gps\\OS201901_EK60GPS.csv', index=False,float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further resampling can be done for saving the file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
